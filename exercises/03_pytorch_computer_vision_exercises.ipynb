{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_pytorch_computer_vision_exercises.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanjaySaatyaki/pytorch_4_ml_dl/blob/main/exercises/03_pytorch_computer_vision_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 03. PyTorch Computer Vision Exercises\n",
        "\n",
        "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
        "\n",
        "They're a bunch of fun.\n",
        "\n",
        "You're going to get to write plenty of code!\n",
        "\n",
        "## Resources\n",
        "\n",
        "1. These exercises are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/).\n",
        "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA).\n",
        "  * **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
        "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
      ],
      "metadata": {
        "id": "Vex99np2wFVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaeYzOTLwWh2",
        "outputId": "be70dc9a-4919-4b0b-960c-09ab922f77d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri May 16 02:38:37 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P8             13W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Exercises require PyTorch > 1.10.0\n",
        "print(torch.__version__)\n",
        "\n",
        "# TODO: Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "DNwZLMbCzJLk",
        "outputId": "a964b7b6-6d48-4bba-9b18-efd46fa89366"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What are 3 areas in industry where computer vision is currently being used?"
      ],
      "metadata": {
        "id": "FSFX7tc1w-en"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VyWRkvWGbCXj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find."
      ],
      "metadata": {
        "id": "oBK-WI6YxDYa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d1rxD6GObCqh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each.\n",
        "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
      ],
      "metadata": {
        "id": "XeYFEqw8xK26"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ocvOdWKcbEKr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
      ],
      "metadata": {
        "id": "DKdEEFEqxM-8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TqZaJIRMbFtS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
      ],
      "metadata": {
        "id": "lvf-3pODxXYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n"
      ],
      "metadata": {
        "id": "SHjeuN81bHza"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = torchvision.datasets.MNIST(root=\"data\",\n",
        "                                       train=True,\n",
        "                                       transform= transforms.ToTensor(),\n",
        "                                       download=True)"
      ],
      "metadata": {
        "id": "zDU2J4UdVe4-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = torchvision.datasets.MNIST(root=\"data\",\n",
        "                                       train=False,\n",
        "                                       transform=transforms.ToTensor(),\n",
        "                                       download=True)"
      ],
      "metadata": {
        "id": "XD56LMgpe9Hz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes"
      ],
      "metadata": {
        "id": "AX0jcLxpb-zd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Visualize at least 5 different samples of the MNIST training dataset."
      ],
      "metadata": {
        "id": "qxZW-uAbxe_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "fig =plt.figure(figsize=(9,9))\n",
        "row =3\n",
        "col =3\n",
        "for i in range(1,row*col+1):\n",
        "  random_idx = torch.randint(0,len(train_data), size=[1]).item()\n",
        "  image, label = train_data[random_idx]\n",
        "  fig.add_subplot(row,col, i)\n",
        "  plt.imshow(image.squeeze(),cmap=\"gray\")\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "QVFsYi1PbItE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "outputId": "876d4518-9862-4de9-d682-a114393ba59b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x900 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "metadata": {
        "id": "AlVCCKqwgetN",
        "outputId": "068524e7-857d-477c-8d60-847c2d15a912",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
      ],
      "metadata": {
        "id": "JAPDzW0wxhi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_data_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_data_loader = DataLoader(test_data, batch_size=32,shuffle=True)"
      ],
      "metadata": {
        "id": "ALA6MPcFbJXQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
      ],
      "metadata": {
        "id": "bCCVfXk5xjYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class tiny_vvg(nn.Module):\n",
        "  def __init__(self, in_shape, out_shape, hidden_units) -> None:\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=in_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2)\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2)\n",
        "    )\n",
        "    self.classifier=nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*7*7,\n",
        "                  out_features=out_shape)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block_1(x)\n",
        "    # print(x.shape)\n",
        "    x = self.conv_block_2(x)\n",
        "    # print(x.shape)\n",
        "    x = self.classifier(x)\n",
        "    # print(x.shape)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "5IKNF22XbKYS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tiny_vvg_model = tiny_vvg(in_shape = 1, out_shape=len(class_names), hidden_units=10)"
      ],
      "metadata": {
        "id": "QYEZ7LvVPZe3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tiny_vvg_model"
      ],
      "metadata": {
        "id": "98Vtic8Vd9NV",
        "outputId": "ca416c71-984f-4628-e63d-005e41a5b7f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tiny_vvg(\n",
              "  (conv_block_1): Sequential(\n",
              "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CgC4TsTGSKR4",
        "outputId": "e4f1e54f-c084-4ec0-9367-6ae72eedf420",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.7.1)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.6.0+cu124)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.14.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import Accuracy\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=tiny_vvg_model.parameters(), lr=0.1)\n",
        "accuracy = Accuracy(task=\"multiclass\", num_classes=len(class_names)).to(device)"
      ],
      "metadata": {
        "id": "cNzLbhUjQQ8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
      ],
      "metadata": {
        "id": "sf_3zUr7xlhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model, data_loader, optimizer,loss_fn,accuracy_fn,target_device):\n",
        "  train_loss, train_acc=0,0\n",
        "  for batch,(X,y) in enumerate(data_loader):\n",
        "\n",
        "    model.train()\n",
        "    y_logits = model(X)\n",
        "    loss = loss_fn(y_logits,y)\n",
        "    y_pred = torch.softmax(y_logits,dim=1).argmax(dim=1)\n",
        "    acc = accuracy_fn(y_pred,y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss\n",
        "    train_acc += acc\n",
        "\n",
        "  train_loss /= len(data_loader)\n",
        "  train_acc /= len(data_loader)\n",
        "\n",
        "  print(f\"Train loss:{train_loss} | Train Acc: {train_acc}\")\n"
      ],
      "metadata": {
        "id": "DAKRn-cvTAgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model, data_loader,loss_fn, accuracy_fn, target_device):\n",
        "  test_loss,test_acc = 0,0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X,y in data_loader:\n",
        "      y_logits = model(X)\n",
        "\n",
        "      y_preds = torch.softmax(y_logits,dim=1).argmax(dim=1)\n",
        "\n",
        "      loss = loss_fn(y_logits,y)\n",
        "      acc = accuracy_fn(y_preds, y)\n",
        "\n",
        "      test_loss += loss\n",
        "      test_acc +=acc\n",
        "    test_loss /= len(data_loader)\n",
        "    test_acc /= len(data_loader)\n",
        "\n",
        "  print(f\"Test Loss: {test_loss} | Test Acc: {test_acc}\")"
      ],
      "metadata": {
        "id": "bR-5BL72Wniq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = torch.rand(size=(1,28,28)).unsqueeze(dim=0)\n",
        "test_image.shape"
      ],
      "metadata": {
        "id": "XkGczPZrZYOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(torch.arange(0,10))"
      ],
      "metadata": {
        "id": "5vRO0GVljGTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tiny_vvg_model.eval()\n",
        "with torch.inference_mode():\n",
        "  logits = tiny_vvg_model(test_image)\n",
        "y_pred = torch.softmax(logits,dim=1).argmax(dim=1)\n",
        "\n",
        "y_pred_t = torch.softmax(logits,dim=1).argmax()\n",
        "print(y_pred.shape)\n",
        "print(y_pred)\n",
        "\n",
        "print(y_pred_t)\n",
        "print(y_pred_t.shape)"
      ],
      "metadata": {
        "id": "tLGLIqDleXXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "model_train_start_time = timer()\n",
        "epochs = 5\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    train_step(model=tiny_vvg_model,\n",
        "               data_loader=train_data_loader,\n",
        "               optimizer=optimizer,\n",
        "               loss_fn=loss_fn,\n",
        "               accuracy_fn=accuracy,\n",
        "               target_device=device\n",
        "               )\n",
        "    test_step(model=tiny_vvg_model,\n",
        "              data_loader=test_data_loader,\n",
        "              loss_fn=loss_fn,\n",
        "              accuracy_fn=accuracy,\n",
        "              target_device=device)\n"
      ],
      "metadata": {
        "id": "jSo6vVWFbNLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
      ],
      "metadata": {
        "id": "w1CsHhPpxp1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(no_of_pred, model, data):\n",
        "\n",
        "  for i in range(no_of_pred):\n",
        "    rand_idx = torch.randint(low=0,high=len(data),size=[1]).item()\n",
        "    img, label = data[rand_idx]\n",
        "    plt.figure(figsize=(2,2))\n",
        "    plt.imshow(img.squeeze(),cmap=\"gray\")\n",
        "    y_pred = model(img.unsqueeze(dim=0)).softmax(dim=1).argmax(dim=1)\n",
        "    if class_names[y_pred] == class_names[label]:\n",
        "      plt.title(class_names[label], color=\"green\")\n",
        "    else:\n",
        "      plt.title(f\"Predicted Class:{class_names[y_pred]} Actual Class:{class_names[label]}\", color=\"red\")\n",
        "\n",
        "make_predictions(5, tiny_vvg_model, train_data)"
      ],
      "metadata": {
        "id": "_YGgZvSobNxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
      ],
      "metadata": {
        "id": "qQwzqlBWxrpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# See if torchmetrics exists, if not, install it\n",
        "try:\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")\n",
        "    assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend verison should be 0.19.0 or higher\"\n",
        "except:\n",
        "    !pip install -q torchmetrics -U mlxtend # <- Note: If you're using Google Colab, this may require restarting the runtime\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")"
      ],
      "metadata": {
        "id": "vSrXiT_AbQ6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import mlxtend upgraded version\n",
        "import mlxtend\n",
        "print(mlxtend.__version__)\n",
        "assert int(mlxtend.__version__.split(\".\")[1]) >= 19 # should be version 0.19.0 or higher"
      ],
      "metadata": {
        "id": "3U4ohWxY7dz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "tiny_vvg_model = tiny_vvg_model.to(device)\n",
        "tiny_vvg_model.eval()\n",
        "\n",
        "y_pred=[]\n",
        "with torch.inference_mode():\n",
        "  for batch, (X,y) in tqdm(enumerate(test_data_loader)):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    y_pred_logits = tiny_vvg_model(X)\n",
        "    y_pred_labels = torch.argmax(torch.softmax(y_pred_logits,dim=1),dim=1)\n",
        "    y_pred.append()\n",
        "  y_pred = torch.cat(y_pred).cpu()\n",
        "  len(y_pred)"
      ],
      "metadata": {
        "id": "D05oLqEl7g-P",
        "outputId": "84208fee-fb36-420a-fc64-d533e1fefe1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tiny_vvg_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-416fcee02d84>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtiny_vvg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tiny_vvg_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import ConfusionMatrix\n",
        "from mlextnd.plotting import plot_confusion_matrix\n",
        "\n",
        "confmat = ConfusionMatrix(task=\"multiclass\", num_classes=len(class_names))\n",
        "confmat_tensor = confmat(y_pred,target = test_data.targets)\n",
        "\n",
        "fix,ax = plot_confusion_matrix(conf_mat = confmat_tensor.numpy(),\n",
        "                               class_names = class_names,\n",
        "                               figsize=(10,7))"
      ],
      "metadata": {
        "id": "uW5-3nZC8SD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
      ],
      "metadata": {
        "id": "lj6bDhoWxt2y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "leCTsqtSbR5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset.\n",
        "* Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
        "* After visualing these predictions do you think it's more of a modelling error or a data error?\n",
        "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ],
      "metadata": {
        "id": "VHS20cNTxwSi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "78a8LjtdbSZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}